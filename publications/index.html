<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Publications</title>
  <meta name="description" content="AMAAI Lab -- Publications.">
  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="/publications/">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
<link rel="shortcut icon" type ="image/x-icon" href="/images/favicon.ico">



</head>


  <body>

    <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container-fluid">
	<div class="navbar-header">
	  <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar-collapse-1" aria-expanded="false">
		<span class="sr-only">Toggle navigation</span>
		<span class="icon-bar"></span>
		<span class="icon-bar"></span>
		<span class="icon-bar"></span>
	  </button>
	
    <a class="navbar-brand" href="/">AMAAI Lab @ SUTD</a>
	</div>
	<div class="collapse navbar-collapse" id="navbar-collapse-1">
	  <ul class="nav navbar-nav navbar-right">
		<li><a href="/">Home</a></li>
		<li><a href="/team">Team</a></li>
		<li><a href="/vacancies">Vacancies</a></li>
		<li><a href="/publications">Publications</a></li>
		<li><a href="/research">Research</a></li>
	  </ul>
	</div>
  </div>
</div>

<!-- <li><a href="/pictures">(Pics)</a></li> -->


    <div class="container-fluid">
      <div class="row">
        <article class="post">

  <header class="post-header">
    <h1 class="post-title">Publications</h1>
  </header>

  <div class="post-content">
    
<h3 id="2025">2025</h3>
<h2 class="bibliography">2025</h2>
<ol class="bibliography"><li><span id="2024">Kang, J., &amp; Herremans, D. (2025). Are we there yet? A brief survey of Music Emotion Prediction Datasets, Models and Outstanding Challenges. <i>IEEE Transactions on Affective Computing</i>. https://arxiv.org/abs/2406.08809</span></li>
<li><span id="2025">Lanzendörfer, L. A., Lu, T., Perraudin, N., Herremans, D., &amp; Wattenhofer, R. (2025). Coarse-to-Fine Text-to-Music Latent Diffusion. <i>Proceedings of ICASSP</i>. https://openreview.net/pdf/b3dcd6d5d6c26679621a2e6c176455d59658c0a8.pdf</span></li>
<li><span id="2026">Tripathi, A., Patle, V., Jain, A., Pundir, A., Menon, S., Singh, A. K., &amp; Herremans, D. (2025). End-to-End Text-to-SQL with Dataset Selection: Leveraging LLMs for Adaptive Query Generation. <i>Proceedings of IJCNN, Rome, Italy</i>.</span></li>
<li><span id="2027">Guo, R., &amp; Herremans, D. (2025). An exploration of controllability in symbolic music infilling. <i>IEEE Access</i>. https://doi.org/0.1109/ACCESS.2025.3554648</span></li>
<li><span id="2022">Herremans, D., &amp; Low, K. W. (2025). Forecasting Bitcoin Volatility Spikes from Whale Transactions and Cryptoquant Data Using Synthesizer Transformer Models. <i>IEEE Access</i>, <i>13</i>, 117788–117807. https://doi.org/10.1109/ACCESS.2025.3584243</span></li>
<li><span id="2028">Bhandari, K., Chang, S., Lu, T., Enus, F. R., Bradshaw, L. B., Herremans, D., &amp; Colton, S. (2025). ImprovNet: Generating Controllable Musical Improvisations with Iterative Corruption Refinement. <i>Proceedings of IJCNN, Rome, Italy</i>. https://arxiv.org/abs/2502.04522</span></li>
<li><span id="2029">Roy, A., Liu, R., Lu, T., &amp; Herremans, D. (2025). JamendoMaxCaps: A Large Scale Music-caption Dataset with Imputed Metadata. <i>Proceedings of IJCNN, Rome, Italy</i>. https://arxiv.org/abs/2502.07461</span></li>
<li><span id="2030">Liu, R., Roy, A., &amp; Herremans, D. (2025). <i>Leveraging LLM Embeddings for Cross Dataset Label Alignment and Zero Shot Music Emotion Prediction</i>. https://arxiv.org/abs/2410.11522</span></li>
<li><span id="2031">Song, M., Pala, T. D., Jin, W., Zadeh, A., Li, C., Herremans, D., &amp; Poria, S. (2025). LLMs Can’t Handle Peer Pressure: Crumbling under Multi-Agent Social Interactions. <i>ArXiv:2508.18321</i>. https://arxiv.org/abs/2508.18321</span></li>
<li><span id="2032">Lu, T., Geist, C.-M., Melechovsky, J., Roy, A., &amp; Herremans, D. (2025). MelodySim: Measuring Melody-aware Music Similarity for Plagiarism Detection. <i>ArXiv:2505.20979</i>. https://arxiv.org/abs/2505.20979</span></li>
<li><span id="2033">Le, D.-V.-T., Bigo, L., Keller, M., &amp; Herremans, D. (2025). Natural Language Processing Methods for Symbolic Music Generation and Information Retrieval: a Survey. <i>ACM Computing Surveys</i>. https://doi.org/https://arxiv.org/abs/2402.17467</span></li>
<li><span id="2034">Lam, P., Zhang, H., Chen, N. F., Sisman, B., &amp; Herremans, D. (2025). PRESENT: Zero-Shot Text-to-Prosody Control. <i>IEEE Signal Processing Letters</i>. https://doi.org/10.1109/LSP.2025.3528359</span></li>
<li><span id="2035">Wei, M., Modrzejewski, M., Sivaraman, A., &amp; Herremans, D. (2025). <i>Prevailing Research Areas for Music AI in the Era of Foundation Models</i>. https://arxiv.org/abs/2409.09378</span></li>
<li><span id="2036">Herremans, D. (2025). <i> Royalties in the age of AI: paying artists for AI-generated songs</i>. https://www.wipo.int/web/wipo-magazine/articles/royalties-in-the-age-of-ai-paying-artists-for-ai-generated-songs-73739</span></li>
<li><span id="2037">Melechovsky, J., Mehrish, A., &amp; Herremans, D. (2025). SonicMaster: Towards Controllable All-in-One Music Restoration and Mastering. <i>ArXiv:2508.03448</i>. https://arxiv.org/abs/2508.03448</span></li>
<li><span id="2038">Chopra, A., Roy, A., &amp; Herremans, D. (2025). SonicVerse: Multi-Task Learning for Music Feature-Informed Captioning. <i>Proceedings of the 6th Conference on AI Music Creativity (AIMC 2025), Brussels, Belgium, September 10th - 12th, 2025</i>. https://arxiv.org/abs/2506.15154</span></li>
<li><span id="2039">Bhandari, K., Roy, A., Wang, K., Puri, G., Colton, S., &amp; Herremans, D. (2025). Text2midi: Generating Symbolic Music from Captions. <i>Proceedings of AAAI, Philadelphia</i>. https://www.arxiv.org/abs/2412.16526</span></li>
<li><span id="2040">Roy, A., Puri, G., &amp; Herremans, D. (2025). Text2midi-InferAlign: Improving Symbolic Music Generation with Inference-Time Alignment. <i>ArXiv:2505.12669</i>. https://arxiv.org/abs/2505.12669</span></li>
<li><span id="2041">Sockalingam, N., Lo, K., Teo, J., Wei, C. C., Chow, D., Herremans, D., Jun, M. L. M., Kurniawan, O., Wang, Y., &amp; Leong, P. K. (2025). Towards the future of education: cyber-physical learning. <i>Discover Education</i>, <i>4</i>, 1–16. https://doi.org/https://doi.org/10.1007/s44217-025-00474-x</span></li>
<li><span id="2042">Kang, J., &amp; Herremans, D. (2025). <i>Towards Unified Music Emotion Recognition across Dimensional and Categorical Models</i>. https://arxiv.org/abs/2502.03979</span></li></ol>

<h3 id="2024">2024</h3>
<h2 class="bibliography">2024</h2>
<ol class="bibliography"><li><span id="2043">Melechovsky, J., Mehrish, A., Sisman, B., &amp; Herremans, D. (2024). Accent Conversion in Text-To-Speech Using Multi-Level VAE and Adversarial Training. <i>Proc. of IEEE Tencon, Singapore</i>. https://arxiv.org/abs/2406.01018</span></li>
<li><span id="2023">Melechovsky, J., Mehrish, A., Sisman, B., &amp; Herremans, D. (2024). Accented Text-to-Speech Synthesis with a Conditional Variational Autoencoder. <i>Proc. of IEEE Tencon, Singapore</i>. https://arxiv.org/abs/2211.03316</span></li>
<li><span id="2044">Luo, J., Yang, X., &amp; Herremans, D. (2024). BandControlNet: Parallel Transformers-based Steerable Popular Music Generation with Fine-Grained Spatiotemporal Features. <i>ArXiv:2407.10462</i>. https://arxiv.org/abs/2407.10462</span></li>
<li><span id="2045">Lanzendörfer, L. A., Lu, T., Perraudin, N., Herremans, D., &amp; Wattenhofer, R. (2024). Coarse-to-Fine Text-to-Music Latent Diffusion. <i>Audio Imagination: NeurIPS 2024 Workshop</i>.</span></li>
<li><span id="2046">Melechovsky, J., Mehrish, A., Sisman, B., &amp; Herremans, D. (2024). DART: Disentanglement of Accent and Speaker Representation in Multispeaker Text-to-Speech. <i>Audio Imagination: NeurIPS 2024 Workshop</i>. https://arxiv.org/abs/2410.13342</span></li>
<li><span id="2047">Ong, J., &amp; Herremans, D. (2024). DeepUnifiedMom: Unified Time-series Momentum Portfolio Construction via Multi-Task Learning with Multi-Gate Mixture of Experts. <i>ArXiv:2406.08742</i>. https://arxiv.org/abs/2406.08742</span></li>
<li><span id="2048">Wang, K., &amp; Herremans, D. (2024). DisfluencySpeech – Single-Speaker Conversational Speech Dataset with Paralanguage. <i>Proc. of IEEE Tencon, Singapore</i>. https://arxiv.org/abs/2406.08820</span></li>
<li><span id="2049">Chow, D., &amp; Herremans, D. (2024). <i>Gamification and skills tree</i>. https://sutd.edu.sg/SUTD/media/SUTD/SUTD-campusX_CPL-Foresight-Report.pdf</span></li>
<li><span id="2050">Melechovsky, J., Roy, A., &amp; Herremans, D. (2024). MidiCaps — A large-scale MIDI dataset with text captions. <i>ISMIR</i>. https://arxiv.org/abs/2406.02255</span></li>
<li><span id="2051">Chopra, A., Roy, A., &amp; Herremans, D. (2024). MIRFLEX: Music Information Retrieval Feature Library for Extraction. <i>ISMIR, Late Breaking Demos</i>. https://arxiv.org/abs/2411.00469</span></li>
<li><span id="2052">Ong, J. (2024). <i>Modern Portfolio Construction with Advanced Deep Learning Models: Vol. PhD</i> [Master's thesis].</span></li>
<li><span id="2053">Melechovsky, J., Guo, Z., Ghosal, D., Majumder, N., Herremans, D., &amp; Poria, S. (2024). Mustango: Toward Controllable Text-to-Music Generation. <i>Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers). Pages 8293–8316</i>. https://doi.org/https://aclanthology.org/2024.naacl-long.pdf</span></li>
<li><span id="2054">Lam, P., Zhang, H., Chen, N. F., Sisman, B., &amp; Herremans, D. (2024). SNIPER Training: Variable Sparsity Rate Training For Text-To-Speech. <i>Proc. of IEEE Tencon, Singapore</i>. https://arxiv.org/abs/2211.07283</span></li>
<li><span id="2055">Kang, J., Poria, S., &amp; Herremans, D. (2024). Video2Music: Suitable Music Generation from Videos using an Affective Multimodal Transformer model. <i>Expert Systems with Applications</i>. https://doi.org/https://doi.org/10.1016/j.eswa.2024.123640</span></li></ol>

<h3 id="2023">2023</h3>
<h2 class="bibliography">2023</h2>
<ol class="bibliography"><li><span id="2013">Ong, J., &amp; Herremans, D. (2023). Constructing Time-Series Momentum Portfolios with Deep Multi-Task Learning. <i>Expert Systems with Applications</i>, <i>230</i>. https://doi.org/10.1016/j.eswa.2023.120587</span></li>
<li><span id="2056">Cheuk, K. W., Sawata, R., Uesaka, T., Murata, N., Takahashi, N., Takahashi, S., Herremans, D., &amp; Mitsufuji, Y. (2023). DiffRoll: Diffusion-based Generative Music Transcription with Unsupervised Pretraining Capability. <i>ICASSP</i>.</span></li>
<li><span id="2057">Guo, Z., Kang, J., &amp; Herremans, D. (2023). A Domain-Knowledge-Inspired Music Embedding Space and a Novel Attention Mechanism for Symbolic Music Modeling. <i>Proceedings of the 37th AAAI Conference on Artificial Intelligence</i>.</span></li>
<li><span id="2058">Melechovsky, J., Mehrish, A., Herremans, D., &amp; Sisman, B. (2023). Learning accent representation with multi-level VAE towards controllable speech synthesis. <i> IEEE Spoken Language Technology (SLT) Workshop</i>.</span></li>
<li><span id="2059">Koh, E., Cheuk, K. W., Heung, K. Y., Agres, K., &amp; Herremans, D. (2023). MERP: A Music Dataset with Emotion Ratings and Raters’ Profile Information. <i>Sensors - Intelligent Sensors</i>, <i>23</i>. https://doi.org/10.3390/s23010382</span></li>
<li><span id="2060">Zou, Y., &amp; Herremans, D. (2023). A Multimodal Model with Twitter Finbert Embeddings for Extreme Price Movement Prediction of Bitcoin. <i>Expert Systems with Applications</i>. https://doi.org/https://doi.org/10.1016/j.eswa.2023.120838</span></li></ol>


  </div>

</article>

      </div>
    </div>

    <div id="footer" class="panel">
  <div class="panel-footer">
	<div class="container-fluid">
	  <div class="row">
		<div class="col-sm-6">
			
		  <p>&copy 2025 AMAAI Lab. Site made with <a href="https://jekyllrb.com">Jekyll</a></p>
              <p>We are part of the <a href="https://www.sutd.edu.sg/istd">Information Systems Technology and Design (ISTD)</a> at <a href="https://www.sutd.edu.sg">Singapore University of Technology and Design</a>.</p>
            

		   <p>  </p><p>
            		  
            
		</div>
		<!--
		<div class="col-sm-4">
		  Funding:<br />
		  - <a href="http://www.nwo.nl/en/research-and-results/programmes/Talent+Scheme">Vidi </a> and <a href='https://www.fom.nl/en/news/press-releases/2016/11/18/28634/'>Projectruimte</a> grants from <a href="http://www.nwo.nl">NWO</a> <br />
		  - <a href="https://www.universiteitleiden.nl/en/research/research-projects/science/frontiers-of-nanoscience-nanofront">Frontier of Nanosciences</a>, a gravity program from <a href="http://www.nwo.nl">NWO</a>
          - <a href='https://www.universiteitleiden.nl/en/news/2017/08/two-erc-grants-for-leiden-physics'>ERC starting grant</a>
		</div>

		  
		<a href="/aboutwebsite.html">copy and  modify it for your own research group.</a>
		-->
		  
		<div class="col-sm-6">
		  Contact:<br />
		  DARES Lab, Level 3, Building 3, Singapore University of Technology and Design, 8 Somapah Rd, Singapore, 487372<br />
          (<a href="https://maps.app.goo.gl/1Y8VMr2WbGXLXGY2A">Maps</a>, <a href="https://www.sutd.edu.sg/contact-us/getting-around-sutd/">Directions</a>)
		</div>
	  </div>
	</div>
  </div>
</div>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
<script src="/js/bootstrap.min.js"></script>


  </body>

</html>
